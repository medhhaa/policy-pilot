import streamlit as st
from retrieval import build_faiss_index, query_faiss
from llm_agent import answer_query

st.set_page_config(page_title="policyâ€‘pilot")
st.title("ğŸ§­ policyâ€‘pilot: Compliance Q&A")

if st.button("ğŸ”¨ Build / Refresh Index"):
    with st.spinner("Indexing chunksâ€¦"):
        build_faiss_index()
    st.success("Index built!")

query = st.text_input("Ask a compliance questionâ€¦")
if st.button("ğŸ’¬ Get Answer"):
    if not query:
        st.error("Please enter a question.")
    else:
        with st.spinner("Retrieving contextâ€¦"):
            chunks = query_faiss(query, top_k=3)
        st.subheader("ğŸ” Retrieved Chunks")
        for i, c in enumerate(chunks, 1):
            st.write(f"**{i}.** {c['text']}")
        with st.spinner("Generating answerâ€¦"):
            answer = answer_query(query, chunks)
        st.subheader("ğŸ¤– policyâ€‘pilot Answer")
        st.write(answer)
